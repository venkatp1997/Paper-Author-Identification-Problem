{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as pi\n",
    "import tfidf\n",
    "import vecfeature\n",
    "import random\n",
    "import traintest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from operator import itemgetter\n",
    "import unsupervised\n",
    "import pandas as pd\n",
    "import levenshtein\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_forest(authorID,paperIDs,aP,aKw,kWp,jKw,PJ,A,T,args1,args2,aff_Author,aff_PaperAuthor):\n",
    "    (pos,neg)=train_test(authorID,aKw,kWp,aP,jKw,PJ,A,T,aff_Author,aff_PaperAuthor)\n",
    "    pos_out=[1]*len(pos)\n",
    "    neg_out=[-1]*len(neg)\n",
    "    pos+=neg\n",
    "    for i in pos:\n",
    "        for j in i:\n",
    "            if math.isnan(j) or j==float('Inf'):\n",
    "                j=500\n",
    "    pos_out+=neg_out\n",
    "    clfRF=RandomForestClassifier()\n",
    "    clfRF.fit(pos,pos_out)\n",
    "    test=[]\n",
    "    predicted_pos=[]\n",
    "    predicted_neg=[]\n",
    "    for i in paperIDs:\n",
    "        test.append(vec(i,authorID,aKw,kWp,aP,jKw,PJ,A,T,aff_Author,aff_PaperAuthor))\n",
    "    clfO=clfRF.predict(test)\n",
    "    for i in range(len(clfO)):\n",
    "        if clfO[i]==1:\n",
    "            predicted_pos.append(paperIDs[i])\n",
    "        else:\n",
    "            predicted_neg.append(paperIDs[i])\n",
    "    ans=[]\n",
    "    ans_pos_sort=[]\n",
    "    for i in range(len(predicted_pos)):\n",
    "        ans_pos_sort.append((predicted_pos[i],unsupervised.score_of_lists(args1,args2[predicted_pos[i]])))\n",
    "    ans_pos_sort=sorted(ans_pos_sort,key=itemgetter(1))\n",
    "    ans_pos_sort[:]=ans_pos_sort[::-1]\n",
    "\n",
    "    ans_neg_sort=[]\n",
    "    for i in range(len(predicted_neg)):\n",
    "        ans_neg_sort.append((predicted_neg[i],unsupervised.score_of_lists(args1,args2[predicted_neg[i]])))\n",
    "    ans_neg_sort=sorted(ans_neg_sort,key=itemgetter(1))\n",
    "    ans_neg_sort[:]=ans_neg_sort[::-1]\n",
    "\n",
    "    for i in ans_pos_sort:\n",
    "        ans.append(i[0])\n",
    "    for i in ans_neg_sort:\n",
    "        ans.append(i[0])\n",
    "    return ans\n",
    "def svm(authorID,paperIDs,aP,aKw,kWp,jKw,PJ,A,T,args1,args2):\n",
    "    (pos,neg)=traintest.train_test(authorID,aKw,kWp,aP,jKw,PJ,A,T)\n",
    "    pos_out=[1]*len(pos)\n",
    "    neg_out=[-1]*len(neg)\n",
    "    if(len(pos)!=0):\n",
    "        pos+=neg\n",
    "        pos_out+=neg_out\n",
    "        clfRF=SVC()\n",
    "        clfRF.fit(pos,pos_out)\n",
    "        test=[]\n",
    "        predicted_pos=[]\n",
    "        predicted_neg=[]\n",
    "        for i in paperIDs:\n",
    "            test.append(vec(i,authorID,aKw,kWp,aP,jKw,PJ,A,T,aff_Author,aff_PaperAuthor))\n",
    "            clfO=clfRF.predict(test)\n",
    "        for i in range(len(clfO)):\n",
    "            if clfO[i]==1:\n",
    "                predicted_pos.append(paperIDs[i])\n",
    "            else:\n",
    "                predicted_neg.append(paperIDs[i])\n",
    "    else:\n",
    "        predicted_pos=[]\n",
    "        predicted_neg=[]\n",
    "        for i in paperIDs:\n",
    "            predicted_neg.append(i)\n",
    "    ans=[]\n",
    "    ans_pos_sort=[]\n",
    "    for i in range(len(predicted_pos)):\n",
    "        ans_pos_sort.append((predicted_pos[i],unsupervised.score_of_lists(args1,args2[predicted_pos[i]])))\n",
    "    ans_pos_sort=sorted(ans_pos_sort,key=itemgetter(1))\n",
    "    ans_pos_sort[:]=ans_pos_sort[::-1]\n",
    "\n",
    "    ans_neg_sort=[]\n",
    "    for i in range(len(predicted_neg)):\n",
    "        ans_neg_sort.append((predicted_neg[i],unsupervised.score_of_lists(args1,args2[predicted_neg[i]])))\n",
    "    ans_neg_sort=sorted(ans_neg_sort,key=itemgetter(1))\n",
    "    ans_neg_sort[:]=ans_neg_sort[::-1]\n",
    "\n",
    "    for i in ans_pos_sort:\n",
    "        ans.append(i[0])\n",
    "    for i in ans_neg_sort:\n",
    "        ans.append(i[0])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fdb84301dc6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthorID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpaperIDs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maKw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkWp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjKw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPJ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-28a51b524b99>\u001b[0m in \u001b[0;36mrandom_forest\u001b[0;34m(authorID, paperIDs, aP, aKw, kWp, jKw, PJ, A, T)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mans_neg_sort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mans_neg_sort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munsupervised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_of_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maKw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthorID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkWp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_neg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mans_neg_sort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_neg_sort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mans_neg_sort\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mans_neg_sort\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/venkat/SMAI-Project/unsupervised.py\u001b[0m in \u001b[0;36mscore_of_lists\u001b[0;34m(l1, l2)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mscore_of_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "random_forest(authorID,paperIDs,aP,aKw,kWp,jKw,PJ,A,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aKw\n",
      "kWp\n",
      "aP\n",
      "jKw\n",
      "PJ\n",
      "A\n",
      "TF-IDF Done\n",
      "aff_Author\n",
      "aff_PaperAuthor\n"
     ]
    }
   ],
   "source": [
    "aKw=pi.load(open(\"aKw.p\",\"rb\"))\n",
    "print (\"aKw\")\n",
    "kWp=pi.load(open(\"kWp.p\",\"rb\"))\n",
    "print (\"kWp\")\n",
    "aP=pi.load(open(\"aP1.p\",\"rb\"))\n",
    "print (\"aP\")\n",
    "jKw=pi.load(open(\"jKw.p\",\"rb\"))\n",
    "print (\"jKw\")\n",
    "PJ=pi.load(open(\"PJ.p\",\"rb\"))\n",
    "print (\"PJ\")\n",
    "A=pi.load(open(\"A.p\",\"rb\"))\n",
    "print (\"A\")\n",
    "T=tfidf.tfidf(\"aKw.p\")\n",
    "args=[]\n",
    "for i in aP:\n",
    "    args.append(i)\n",
    "T.create(args)\n",
    "print (\"TF-IDF Done\")\n",
    "aff_Author=pi.load(open(\"aff_Author.p\",\"rb\"))\n",
    "print (\"aff_Author\")\n",
    "aff_PaperAuthor=pi.load(open(\"aff_PaperAuthor.p\",\"rb\"))\n",
    "print (\"aff_PaperAuthor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "24943",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a9c8a2fd450b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#                 args2[j].append((k,T.calculate(authorID,k)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#     print (\"Args-2 Done\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthorID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpaperIDs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maKw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkWp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjKw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPJ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maff_Author\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maff_PaperAuthor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#     ret1=svm(authorID,paperIDs,aP,aKw,kWp,jKw,PJ,A,T,args1,args2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthorID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-851085c8a394>\u001b[0m in \u001b[0;36mrandom_forest\u001b[0;34m(authorID, paperIDs, aP, aKw, kWp, jKw, PJ, A, T, args1, args2, aff_Author, aff_PaperAuthor)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mans_neg_sort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mans_neg_sort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_neg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munsupervised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_of_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_neg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mans_neg_sort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_neg_sort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mans_neg_sort\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mans_neg_sort\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 24943"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"/home/venkat/Downloads/Test.csv\")\n",
    "input1=[]\n",
    "for (index,i) in data.iterrows():\n",
    "    in1=i[\"PaperIds\"].split()\n",
    "    in1=[int(i) for i in in1]\n",
    "    in2=int(i[\"AuthorId\"])\n",
    "    input1.append((in1,in2))\n",
    "f=open(\"output1.csv\",\"w\")\n",
    "f.write(\"AuthorId,PaperIds\")\n",
    "f.write(\"\\n\")\n",
    "f1=open(\"output2.csv\",\"w\")\n",
    "f1.write(\"AuthorId,PaperIds\")\n",
    "f1.write(\"\\n\")\n",
    "no=0\n",
    "for i in input1:\n",
    "    args1=[]\n",
    "    args2={}\n",
    "    authorID=i[1]\n",
    "    paperIDs=i[0]\n",
    "    if authorID in aKw:\n",
    "        for j in aKw[authorID]:\n",
    "            args1.append((j,T.calculate(authorID,j)))\n",
    "#     print (\"Args-1 Done\")\n",
    "    for j in paperIDs:\n",
    "        args2[j]=[]\n",
    "        if str(j) in kWp:\n",
    "            for k in kWp[str(j)]:\n",
    "                args2[j].append((k,T.calculate(authorID,k)))\n",
    "#     print (\"Args-2 Done\")\n",
    "    ret=random_forest(authorID,paperIDs,aP,aKw,kWp,jKw,PJ,A,T,args1,args2,aff_Author,aff_PaperAuthor)\n",
    "    ret1=svm(authorID,paperIDs,aP,aKw,kWp,jKw,PJ,A,T,args1,args2)\n",
    "    f.write(str(authorID))\n",
    "    f.write(\",\")\n",
    "    for j in ret:\n",
    "        f.write(str(j))\n",
    "        f.write(\" \")\n",
    "    f.write(\"\\n\")\n",
    "    f1.write(str(authorID))\n",
    "    f1.write(\",\")\n",
    "    for j in ret1:\n",
    "        f1.write(str(j))\n",
    "        f1.write(\" \")\n",
    "    f1.write(\"\\n\")\n",
    "    no+=1\n",
    "    print (no)\n",
    "f.close()\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(authorID,aKw,kWp,aP,jKw,PJ,A,T,aff_Author,aff_PaperAuthor):\n",
    "    pos=[]\n",
    "    neg=[]\n",
    "    neg_sample_paperIDs=[]\n",
    "    if authorID in aP:\n",
    "        for i in aP[authorID]:\n",
    "            pos.append(vec(i,authorID,aKw,kWp,aP,jKw,PJ,A,T,aff_Author,aff_PaperAuthor))\n",
    "    len_neg=2*(len(pos)+1)\n",
    "    while True:\n",
    "        neg_sample_keys=random.sample(list(aP),len_neg)\n",
    "        neg_sample=[]\n",
    "        flag=0\n",
    "        for i in neg_sample_keys:\n",
    "            if i==authorID:\n",
    "                flag=1\n",
    "        if flag==0:\n",
    "            for i in neg_sample_keys:\n",
    "                neg_sample.append(aP[i])\n",
    "            break\n",
    "    for i in neg_sample:\n",
    "        for j in i:\n",
    "            neg_sample_paperIDs.append(j)\n",
    "    for i in neg_sample_paperIDs:\n",
    "        neg.append(vec(i,authorID,aKw,kWp,aP,jKw,PJ,A,T,aff_Author,aff_PaperAuthor))\n",
    "    return (pos,neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec(paperID,authorID,aKw,kWp,aP,jKw,PJ,A,T,aff_Author,aff_PaperAuthor,nb_flag=0):\n",
    "    vector=np.empty(0)\n",
    "    #Feature-1\n",
    "    ret=vecfeature.matching_keywords_pa(aKw,kWp,paperID,authorID)\n",
    "    # print (ret)\n",
    "    # print (\"Ret Done\")\n",
    "    temp=np.zeros(50000)\n",
    "    cnt=0\n",
    "    for keyword in ret:\n",
    "        if len(keyword)==0: continue\n",
    "        temp[cnt]=T.calculate(authorID,keyword)\n",
    "        cnt+=1\n",
    "        # if(cnt%1000)==0: print (\"Feature-1 Going on..\")\n",
    "    temp=np.resize(temp,cnt)\n",
    "    temp=np.sort(temp,axis=None)\n",
    "    temp[:]=temp[::-1]\n",
    "    j=0\n",
    "    for i in temp:\n",
    "        vector=np.append(vector,i)\n",
    "        j+=1\n",
    "        if(j>=5): break\n",
    "    for k in range(j,5):\n",
    "        vector=np.append(vector,0)\n",
    "    if(nb_flag==1):\n",
    "        #Feature-1_neg\n",
    "        ret=vecfeature.matching_keywords_pa_neg(aKw,kWp,paperID,authorID)\n",
    "        temp=np.zeros(50000)\n",
    "        cnt=0\n",
    "        for keyword in ret:\n",
    "            if len(keyword)==0: continue\n",
    "            temp[cnt]=T.calculate(authorID,keyword)\n",
    "            cnt+=1\n",
    "        temp=np.resize(temp,cnt)\n",
    "        temp=np.sort(temp,axis=None)\n",
    "        temp[:]=temp[::-1]\n",
    "        j=0\n",
    "        for i in temp:\n",
    "            vector=np.append(vector,i)\n",
    "            j+=1\n",
    "            if(j>=5): break\n",
    "        for k in range(j,5):\n",
    "            vector=np.append(vector,0)\n",
    "\n",
    "    journalID=vecfeature.get_journal(PJ,paperID)\n",
    "    # print (\"Feature-1 Done\")\n",
    "    #Feature-2\n",
    "    ret=vecfeature.matching_keywords_aj(aKw,jKw,journalID,authorID)\n",
    "    # print (ret)\n",
    "    temp=np.zeros(50000)\n",
    "    cnt=0\n",
    "    for keyword in ret:\n",
    "        if len(keyword)==0: continue\n",
    "        temp[cnt]=T.calculate(authorID,keyword)\n",
    "        cnt+=1\n",
    "    temp=np.resize(temp,cnt)\n",
    "    temp=np.sort(temp,axis=None)\n",
    "    temp[:]=temp[::-1]\n",
    "    j=0\n",
    "    for i in temp:\n",
    "        vector=np.append(vector,i)\n",
    "        j+=1\n",
    "        if(j>=3): break\n",
    "    for k in range(j,3):\n",
    "        vector=np.append(vector,0)\n",
    "    # print (\"Feature-2 Done\")\n",
    "    if(nb_flag==1):\n",
    "        #Feature-2_neg\n",
    "        ret=vecfeature.matching_keywords_aj_neg(aKw,jKw,journalID,authorID)\n",
    "        temp=np.zeros(50000)\n",
    "        cnt=0\n",
    "        for keyword in ret:\n",
    "            if len(keyword)==0: continue\n",
    "            temp[cnt]=T.calculate(authorID,keyword)\n",
    "            cnt+=1\n",
    "        temp=np.resize(temp,cnt)\n",
    "        temp=np.sort(temp,axis=None)\n",
    "        temp[:]=temp[::-1]\n",
    "        j=0\n",
    "        for i in temp:\n",
    "            vector=np.append(vector,i)\n",
    "            j+=1\n",
    "            if(j>=8): break\n",
    "        for k in range(j,8):\n",
    "            vector=np.append(vector,0)\n",
    "\n",
    "    #Feature-3\n",
    "    ret=vecfeature.get_authors(A,paperID)\n",
    "    temp=np.zeros(50000)\n",
    "    cnt=0\n",
    "    for i in ret:\n",
    "        if i==authorID: continue\n",
    "        temp[cnt]=vecfeature.matching_papers(aP,i,authorID)\n",
    "        # if(cnt%1000)==0: print (\"Feature-3 Going on..\")\n",
    "        cnt+=1\n",
    "    temp=np.resize(temp,cnt)\n",
    "    temp=np.sort(temp,axis=None)\n",
    "    temp[:]=temp[::-1]\n",
    "    j=0\n",
    "    for i in temp:\n",
    "        vector=np.append(vector,i)\n",
    "        j+=1\n",
    "        if(j>=4): break\n",
    "    for k in range(j,4):\n",
    "        vector=np.append(vector,0)\n",
    "    if(nb_flag==1):\n",
    "        #Feature-3_neg\n",
    "        ret=vecfeature.get_authors(A,paperID)\n",
    "        temp=np.zeros(50000)\n",
    "        cnt=0\n",
    "        for i in ret:\n",
    "            if i==authorID: continue\n",
    "            temp[cnt]=vecfeature.matching_papers_neg(aP,i,authorID)\n",
    "            cnt+=1\n",
    "        temp=np.resize(temp,cnt)\n",
    "        temp=np.sort(temp,axis=None)\n",
    "        temp[:]=temp[::-1]\n",
    "        j=0\n",
    "        for i in temp:\n",
    "            vector=np.append(vector,i)\n",
    "            j+=1\n",
    "            if(j>=4): break\n",
    "        for k in range(j,4):\n",
    "            vector=np.append(vector,0)\n",
    "    # print (\"Feature-3 Done\")\n",
    "    #Feature 4\n",
    "    vector=np.append(vector,vecfeature.noKeywords_Author(aKw,authorID))\n",
    "    # print (\"Feature-4 Done\")\n",
    "    #Feature 5\n",
    "    vector=np.append(vector,vecfeature.noKeywords_Paper(kWp,paperID))\n",
    "    # print (\"Feature-5 Done\")\n",
    "    word1=\"\"\n",
    "    word2=\"\"\n",
    "    max2=0\n",
    "    max3=0\n",
    "    min4=500\n",
    "    min5=500\n",
    "    if authorID in aff_Author:\n",
    "        word1=aff_Author[authorID]\n",
    "    if authorID in aff_PaperAuthor:\n",
    "        word2=aff_PaperAuthor[authorID]\n",
    "    vector=np.append(vector,levenshtein.distance(word1,word2))\n",
    "    if paperID in A:\n",
    "        for i in A[paperID]:\n",
    "            word3=\"\"\n",
    "            word4=\"\"\n",
    "            if i not in aff_Author and len(word1)==0:\n",
    "                max2=max(max2,18.976)\n",
    "                min4=min(min4,18.976)\n",
    "            if i not in aff_PaperAuthor and len(word2)==0:\n",
    "                max3=max(max3,18.65)\n",
    "                min5=min(min5,18.65)\n",
    "            if i in aff_Author:\n",
    "                word3=aff_Author[i]\n",
    "                max2=max(max2,levenshtein.distance(word1,word3))\n",
    "                min4=min(min4,levenshtein.distance(word1,word3))\n",
    "            if i in aff_PaperAuthor:\n",
    "                word4=aff_PaperAuthor[i]\n",
    "                max3=max(max3,levenshtein.distance(word2,word4))\n",
    "                min5=min(min5,levenshtein.distance(word2,word4))\n",
    "            if i not in aff_Author and len(word1)!=0:\n",
    "                max2=max(max2,levenshtein.distance(word1,word3))\n",
    "                min4=min(min4,levenshtein.distance(word1,word3))\n",
    "            if i not in aff_PaperAuthor and len(word2)!=0:\n",
    "                max3=max(max3,levenshtein.distance(word2,word4))\n",
    "                min5=min(min5,levenshtein.distance(word2,word4))\n",
    "    vector=np.append(vector,max2)\n",
    "    vector=np.append(vector,max3)\n",
    "    vector=np.append(vector,min4)\n",
    "    vector=np.append(vector,min5)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
